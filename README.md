# Scratch Linear Models and Basic Neural Network<br>

In this GitHub repository, we will explore the fundamentals of building linear models and basic neural networks from scratch using Python. The primary focus will be on understanding the underlying concepts and implementing them step by step. We will use the Titanic Survival Prediction dataset as an example to demonstrate the entire process.

## 1. Dataset used: Titanic Survival Prediction dataset

We will work with the Titanic dataset, which contains information about passengers on the Titanic, including whether they survived or not. The goal is to predict the survival status of passengers based on various features such as age, gender, ticket class, etc.

## 2. Data Preprocessing

Before building our models, we will preprocess the dataset by handling missing values, encoding categorical variables, and splitting the data into training and testing sets.

## 3. Feature Engineering

We will explore feature engineering techniques to create new features or transform existing ones to improve the model's predictive power.

## 4. Creating a Linear Model from Scratch

We will start by implementing a simple linear model from scratch. This involves defining a hypothesis function, cost function, and performing gradient descent to optimize the model's parameters.

## 5. Adding a gradient descent step

We will add a gradient descent step to our linear model to update the model parameters iteratively and minimize the cost function.

## 6. Training Linear Model

We will train our linear model using the training data, adjusting the model's parameters to fit the data.

## 7. Evaluating model performance and Using Sigmoid Function

We will evaluate the performance of our linear model, using metrics like accuracy and precision. Additionally, we will introduce the sigmoid function to make our linear model suitable for binary classification tasks.

## 8. Testing the model on test data

Once the linear model is trained, we will test it on the test dataset to assess its performance on unseen data.

## 9. Using matrix multiplication instead of element-wise multiplication

To optimize our linear model's computation, we will transition from element-wise operations to matrix multiplications, making it more efficient.

## 10. Creating a basic neural network with a single hidden layer

We will delve into neural networks by building a basic architecture with a single hidden layer. This involves defining the forward and backward propagation steps, as well as training the neural network.

## 11. Creating a Deep Neural network from scratch:

Taking our understanding further, we will create a deep neural network from scratch, introducing multiple hidden layers, activation functions, and demonstrating backpropagation to train deeper architectures.

This repository provides Python code examples, Jupyter notebooks, and explanatory documentation for each step of the process. By following along, you will gain a solid understanding of linear models and basic neural networks, paving the way for more advanced machine learning and deep learning concepts.

Feel free to explore the code and documentation in this repository to deepen your understanding of these fundamental machine learning and deep learning concepts. Happy learning!
